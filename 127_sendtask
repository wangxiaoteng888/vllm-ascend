import torch_npu


@dataclass
class SendTask:
    send_request: dict[str, ReqMeta] = field(default_factory=dict)
    # pd_head_ratio == 1 use
    wait_event: Optional[torch.npu.Event] = None
    # pd_head_ratio > 1 use
    k_cache: Optional[torch.Tensor] = None
    v_cache: Optional[torch.Tensor] = None
    layer_idx: int = 0
    # trans block info
    rearrange_block_ids: Optional[list[int]] = None
    num_blocks: Optional[int] = None
    num_tokens: Optional[int] = None
    block_table: Optional[torch.Tensor] = None
    block_len_tensor: Optional[torch.Tensor] = None
    seq_start_tensor: Optional[torch.Tensor] = None
class MooncakeLayerwiseConnectorMetadata(KVConnectorMetadata):

    def __init__(self):
        self.requests: dict[str, ReqMeta] = {}
        self.send_task: SendTask = SendTask()
self.total_layers = vllm_config.model_config.get_num_layers(
            vllm_config.parallel_config)
        self.use_mla= self.vllm_config.model_config.use_mla
def start_load_kv(self, metadata: MooncakeLayerwiseConnectorMetadata):
        """Start loading KV blocks from remote engine."""
        self.current_layer = 0
        if self.vllm_config.kv_transfer_config.is_kv_consumer:
            for req_id, meta in metadata.requests.items():
                assert self.kv_recv_layer_thread is not None
                with self.kv_recv_layer_thread.lock:
                    self.kv_recv_layer_thread.task_tracker[req_id] = 0
        elif self.vllm_config.kv_transfer_config.is_kv_producer:
            # select req to send
            if self.use_mla or self.use_sparse:
                num_need_send = self._decode_tp_size
            else:
                num_kv_head = self.vllm_config.model_config.hf_config.num_key_value_heads
                if self.tp_size <= num_kv_head:
                    num_need_send = self.tp_size
                else:
                    num_need_send = self._decode_tp_size if self._decode_tp_size >= num_kv_head else num_kv_head
            num_replica_groups = self.tp_size // num_need_send if self.tp_size >= num_need_send else 1
            replica_group_idx = self.tp_rank % num_replica_groups
            req_ids = sorted(list(metadata.requests.keys()))
            selected_req_ids = [
                req_id for i, req_id in enumerate(req_ids)
                if i % num_replica_groups == replica_group_idx
            ]
            # print(f"[===] {selected_req_ids=}")
            request_ids = list(metadata.requests.keys())
            for req_id in request_ids:
                if req_id not in selected_req_ids:
                    metadata.requests.pop(req_id)

            # update send task trans block info
            if self.pd_head_ratio != 1:
                send_task = metadata.send_task
                send_task.rearrange_block_ids = sorted({
                    block_id
                    for req_id in selected_req_ids
                    for block_id in
                    metadata.requests[req_id].local_block_ids
                })

                device = self.k_buffer.device
                flat_block_ids = send_task.rearrange_block_ids
                block_ids_tensor = torch.tensor(flat_block_ids,
                                                dtype=torch.int32,
                                                device=device)
                send_task.num_blocks = len(flat_block_ids)
                send_task.num_tokens = send_task.num_blocks * self.block_size

                send_task.block_table = block_ids_tensor.view(1, -1)
                send_task.block_len_tensor = torch.tensor([send_task.num_tokens],
                                                dtype=torch.int32,
                                                device=device)
                send_task.seq_start_tensor = torch.tensor([0], dtype=torch.int32, device=device)

    def save_kv_layer(self, layer_name: str, kv_layer: Tuple[torch.Tensor,
                                                             torch.Tensor],
                      attn_metadata: "AttentionMetadata",
                      connector_metadata: MooncakeLayerwiseConnectorMetadata,
                      **kwargs) -> None:
        """MooncakeLayerwiseConnector does not save explicitly."""
        if self.vllm_config.kv_transfer_config.is_kv_producer and connector_metadata.requests.keys(
        ):
        # enable decode prefix cache
            if self.use_mla or self.use_sparse:
                reshape_cache_event = attn_metadata[
                    layer_name].reshape_cache_event
            else:
                reshape_cache_event = attn_metadata.reshape_cache_event

            send_task = connector_metadata.send_task
            if self.pd_head_ratio != 1:
                assert self.resharding_stream is not None
                with npu_stream_switch(self.resharding_stream):
                    reshape_cache_event.wait()
                    dtype = self.k_buffer.dtype
                    device = self.k_buffer.device
                    # Initialize buffers
                    keys = torch.empty(
                        (send_task.num_tokens, *kv_layer[0].size()[-2:]),
                        dtype=dtype,
                        device=device)
                    values = torch.empty(
                        (send_task.num_tokens, *kv_layer[1].size()[-2:]),
                        dtype=dtype,
                        device=device)

                    # Load cache data into buffers
                    torch_npu.atb.npu_paged_cache_load(kv_layer[0],
                                                    kv_layer[1],
                                                    send_task.block_table,
                                                    send_task.block_len_tensor,
                                                    seq_starts=send_task.seq_start_tensor,
                                                    key=keys,
                                                    value=values)

                    # sort kv caches for each block
                    keys = keys.view(send_task.num_blocks, self.pd_head_ratio, -1,
                                        *keys.shape[1:]).transpose(
                                            0, 1).reshape_as(keys)
                    values = values.view(send_task.num_blocks,
                                            self.pd_head_ratio, -1,
                                            *values.shape[1:]).transpose(
                                                0, 1).reshape_as(values)
                    # reshard kv cache
                    keys = keys.reshape(-1, *kv_layer[0].shape[2:])
                    values = values.reshape(-1, *kv_layer[1].shape[2:])
                    (keys, values) = kv_alltoall_and_rearrange(
                        self.pd_head_ratio, keys, values)
            else:
                keys = None
                values = None

            assert self.kv_send_layer_thread is not None
            assert reshape_cache_event is not None
            layer_send_task = SendTask(wait_event=reshape_cache_event,
                                     k_cache=keys,
                                     v_cache=values,
                                     layer_idx=self.current_layer,
                                     rearrange_block_ids=send_task.rearrange_block_ids)
            for req_id, req_meta in connector_metadata.requests.items():
                req_meta_update = self.update_decoder_info(
                    req_id, req_meta)
                logger.debug(
                    f"Add request {req_id} to kv send layer thread. {req_meta_update=}"
                )
                layer_send_task.send_request[req_id] = req_meta_update

            self.kv_send_layer_thread.send_queue.put(layer_send_task)
            self.current_layer += 1
